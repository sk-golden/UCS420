{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f6c1c7-7a55-4c81-b4de-61276f5e52a1",
   "metadata": {},
   "source": [
    "Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports, technology, food, books, etc.).\r\n",
    "1.\r\n",
    "Convert text to lowercase and remove punctuaƟon2..\r\n",
    "Tokenize the text into words and sentence3.s.\r\n",
    "Remove stopwords (using NLTK's stopwords lis4.t).\r\n",
    "Display word frequency distribuition (excluding stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1ba02b-b17d-4a88-b182-ef5d9a6c00ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/9183e031-2d86-45af-a601-\n",
      "[nltk_data]     bfbb3b8c0477/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/9183e031-2d86-45af-a601-\n",
      "[nltk_data]     bfbb3b8c0477/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d826a209-60f4-4a90-a015-ce4652b7cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokens: ['books are gateways to new worlds allowing us to explore places people and ideas through the written word they educate inspire and sometimes transport us to realms of fantasy and adventure fiction cultivates creativity while nonfiction provides knowledge and perspective the smell of a freshly opened book has an inexplicable charm and digital books offer convenience onthego reading is not just a hobby its a lifelong journey into wisdom and imagination']\n",
      "Filtered Words: ['books', 'gateways', 'new', 'worlds', 'allowing', 'us', 'explore', 'places', 'people', 'ideas', 'written', 'word', 'educate', 'inspire', 'sometimes', 'transport', 'us', 'realms', 'fantasy', 'adventure', 'fiction', 'cultivates', 'creativity', 'nonfiction', 'provides', 'knowledge', 'perspective', 'smell', 'freshly', 'opened', 'book', 'inexplicable', 'charm', 'digital', 'books', 'offer', 'convenience', 'onthego', 'reading', 'hobby', 'lifelong', 'journey', 'wisdom', 'imagination']\n",
      "Word Frequency Distribution: Counter({'books': 2, 'us': 2, 'gateways': 1, 'new': 1, 'worlds': 1, 'allowing': 1, 'explore': 1, 'places': 1, 'people': 1, 'ideas': 1, 'written': 1, 'word': 1, 'educate': 1, 'inspire': 1, 'sometimes': 1, 'transport': 1, 'realms': 1, 'fantasy': 1, 'adventure': 1, 'fiction': 1, 'cultivates': 1, 'creativity': 1, 'nonfiction': 1, 'provides': 1, 'knowledge': 1, 'perspective': 1, 'smell': 1, 'freshly': 1, 'opened': 1, 'book': 1, 'inexplicable': 1, 'charm': 1, 'digital': 1, 'offer': 1, 'convenience': 1, 'onthego': 1, 'reading': 1, 'hobby': 1, 'lifelong': 1, 'journey': 1, 'wisdom': 1, 'imagination': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/9183e031-2d86-45af-a601-\n",
      "[nltk_data]     bfbb3b8c0477/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/9183e031-2d86-45af-a601-\n",
      "[nltk_data]     bfbb3b8c0477/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "\n",
    "text = \"\"\"Books are gateways to new worlds, allowing us to explore places, people, and ideas through the written word. They educate, inspire, and sometimes transport us to realms of fantasy and adventure. Fiction cultivates creativity, while non-fiction provides knowledge and perspective. The smell of a freshly opened book has an inexplicable charm, and digital books offer convenience on-the-go. Reading is not just a hobby; it's a lifelong journey into wisdom and imagination.\"\"\"\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "text = text.lower()\n",
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "sentence_tokens = sent_tokenize(text)\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "\n",
    "word_freq = Counter(filtered_words)\n",
    "\n",
    "print(\"Sentence Tokens:\", sentence_tokens)\n",
    "print(\"Filtered Words:\", filtered_words)\n",
    "print(\"Word Frequency Distribution:\", word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c5993-dddd-4637-b060-eacc54bf8d12",
   "metadata": {},
   "source": [
    "Q2: Stemming and Lemmatization\r\n",
    "1.\r\n",
    "Take the tokenized words from QutisƟon 1 (aŌer stopword removal)2..\r\n",
    "Apply stemming using NLTK's PorterStemmer and LancasterStemme3.r.\r\n",
    "Apply ltimmaƟzaƟon using NLTK's WordNetLtimmaƟz4.er.\r\n",
    "Compare and display results of both techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead69b8d-7735-4a3b-8482-0912d3685d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/9183e031-2d86-45af-a601-\n",
      "[nltk_data]     bfbb3b8c0477/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer: ['book', 'gateway', 'new', 'world', 'allow', 'us', 'explor', 'place', 'peopl', 'idea', 'written', 'word', 'educ', 'inspir', 'sometim', 'transport', 'us', 'realm', 'fantasi', 'adventur', 'fiction', 'cultiv', 'creativ', 'nonfict', 'provid', 'knowledg', 'perspect', 'smell', 'freshli', 'open', 'book', 'inexplic', 'charm', 'digit', 'book', 'offer', 'conveni', 'onthego', 'read', 'hobbi', 'lifelong', 'journey', 'wisdom', 'imagin']\n",
      "Lancaster Stemmer: ['book', 'gateway', 'new', 'world', 'allow', 'us', 'expl', 'plac', 'peopl', 'idea', 'writ', 'word', 'educ', 'inspir', 'sometim', 'transport', 'us', 'realm', 'fantasy', 'adv', 'fict', 'cult', 'cre', 'nonfict', 'provid', 'knowledg', 'perspect', 'smel', 'fresh', 'op', 'book', 'inexpl', 'charm', 'digit', 'book', 'off', 'conveny', 'onthego', 'read', 'hobby', 'lifelong', 'journey', 'wisdom', 'imagin']\n",
      "Lemmatized Words: ['book', 'gateway', 'new', 'world', 'allowing', 'u', 'explore', 'place', 'people', 'idea', 'written', 'word', 'educate', 'inspire', 'sometimes', 'transport', 'u', 'realm', 'fantasy', 'adventure', 'fiction', 'cultivates', 'creativity', 'nonfiction', 'provides', 'knowledge', 'perspective', 'smell', 'freshly', 'opened', 'book', 'inexplicable', 'charm', 'digital', 'book', 'offer', 'convenience', 'onthego', 'reading', 'hobby', 'lifelong', 'journey', 'wisdom', 'imagination']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "stemmed_porter = [porter.stem(word) for word in filtered_words]\n",
    "stemmed_lancaster = [lancaster.stem(word) for word in filtered_words]\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "\n",
    "print(\"Porter Stemmer:\", stemmed_porter)\n",
    "print(\"Lancaster Stemmer:\", stemmed_lancaster)\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f17751-a7af-4a65-ac96-8074400ceb75",
   "metadata": {},
   "source": [
    "Q3. Regular Expressions and Text Spliƫng\r\n",
    "1.\r\n",
    "Take their original text from QutisƟon 12..\r\n",
    "Use regular expressions to: a. Extract all words with more than 5 leƩers. b. Extract all numbers (if any exist in their text). c. Extract all capitalized word3.s.\r\n",
    "Use text spliƫng techniques to: a. Split the text into words containing only alphabets (removing digits and special characters). b. Extract words starƟng with a vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fccf5aa6-d52e-49b6-8bae-f0154a5ec9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with >5 letters: ['gateways', 'worlds', 'allowing', 'explore', 'places', 'people', 'through', 'written', 'educate', 'inspire', 'sometimes', 'transport', 'realms', 'fantasy', 'adventure', 'fiction', 'cultivates', 'creativity', 'nonfiction', 'provides', 'knowledge', 'perspective', 'freshly', 'opened', 'inexplicable', 'digital', 'convenience', 'onthego', 'reading', 'lifelong', 'journey', 'wisdom', 'imagination']\n",
      "Numbers: []\n",
      "Capitalized Words: ['Technology']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "long_words = re.findall(r'\\b\\w{6,}\\b', text)\n",
    "\n",
    "\n",
    "numbers = re.findall(r'\\d+', text)\n",
    "\n",
    "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', \"Technology is reshaping the world.\")\n",
    "\n",
    "print(\"Words with >5 letters:\", long_words)\n",
    "print(\"Numbers:\", numbers)\n",
    "print(\"Capitalized Words:\", capitalized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6e7ba8-71a9-4603-bc0b-5606e91cfaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet words: ['books', 'are', 'gateways', 'to', 'new', 'worlds', 'allowing', 'us', 'to', 'explore', 'places', 'people', 'and', 'ideas', 'through', 'the', 'written', 'word', 'they', 'educate', 'inspire', 'and', 'sometimes', 'transport', 'us', 'to', 'realms', 'of', 'fantasy', 'and', 'adventure', 'fiction', 'cultivates', 'creativity', 'while', 'nonfiction', 'provides', 'knowledge', 'and', 'perspective', 'the', 'smell', 'of', 'a', 'freshly', 'opened', 'book', 'has', 'an', 'inexplicable', 'charm', 'and', 'digital', 'books', 'offer', 'convenience', 'onthego', 'reading', 'is', 'not', 'just', 'a', 'hobby', 'its', 'a', 'lifelong', 'journey', 'into', 'wisdom', 'and', 'imagination']\n",
      "Vowel-starting words: ['are', 'allowing', 'us', 'explore', 'and', 'ideas', 'educate', 'inspire', 'and', 'us', 'of', 'and', 'adventure', 'and', 'of', 'a', 'opened', 'an', 'inexplicable', 'and', 'offer', 'onthego', 'is', 'a', 'its', 'a', 'into', 'and', 'imagination']\n"
     ]
    }
   ],
   "source": [
    "alphabet_words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "\n",
    "\n",
    "vowel_words = [word for word in alphabet_words if word[0] in 'aeiou']\n",
    "\n",
    "print(\"Alphabet words:\", alphabet_words)\n",
    "print(\"Vowel-starting words:\", vowel_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ad8a9-9a8f-4908-8213-034c391b6b50",
   "metadata": {},
   "source": [
    "Q4. Custom TokenizaƟon & Regex-based Text Cleaning\r\n",
    "1.\r\n",
    "Take original text from Question 1.2.\r\n",
    "\r\n",
    "Write a custom tokenization function that: a. Removes punctuation and special symbols, but keeps contractions (e.g., \"isn't\" should not be split into \"is\" and \"n't\"). b. Handles hyphenated words as a single token (e.g., \"state-of-the-art\" remains a single token). c. Tokenizes numbers separately but keeps decimal numbers intact (e.g., \"3.14\" should remain as is3.).\r\n",
    "\r\n",
    "Use Regeti StibsƟtuƟons (re.sub) to: a. Replace email addresses with '' placeholder. b. Replace URLs with '' placeholder. c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with '' placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d372d8ce-216a-47a1-9207-b8a8f3044be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Tokens: ['Contact', 'me', 'at', 'abc', 'example', 'com', 'or', 'visit', 'https', 'example', 'com', 'Call', '91', '9876543210']\n",
      "Cleaned Text: Contact me at  or visit  Call .\n"
     ]
    }
   ],
   "source": [
    "def custom_tokenize(text):\n",
    "\n",
    "    tokens = re.findall(r'\\b\\w[\\w-]*\\b', text)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "text = \"Contact me at abc@example.com or visit https://example.com. Call +91 9876543210.\"\n",
    "cleaned_text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "cleaned_text = re.sub(r'(https?:\\/\\/\\S+|www\\.\\S+)', '', cleaned_text)\n",
    "cleaned_text = re.sub(r'\\+?\\d[\\d -]{8,}\\d', '', cleaned_text)\n",
    "\n",
    "print(\"Custom Tokens:\", custom_tokenize(text))\n",
    "print(\"Cleaned Text:\", cleaned_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
